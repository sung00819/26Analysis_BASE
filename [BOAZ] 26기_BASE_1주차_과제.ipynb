{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "WosjT1B5VeBj",
      "metadata": {
        "id": "WosjT1B5VeBj"
      },
      "source": [
        "# 1. ANN 과제"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "HtX76CHOYLCs",
      "metadata": {
        "id": "HtX76CHOYLCs"
      },
      "source": [
        "## Backpropagation의 가중치 업데이트\n",
        "\n",
        "다음은 17페이지에 제시된 **역전파(Backpropagation) 과정 중 가중치 업데이트 단계**를 나타낸 식이다.\n",
        "\n",
        "가중치 업데이트 단계는 앞선 단계에서 계산된 오차의 기울기를 이용해  \n",
        "손실 함수(Error)를 최소화하는 방향으로 가중치를 조정하는 과정이며,  \n",
        "이때 사용되는 규칙은 대표적인 **최적화 기법**에 해당한다.  \n",
        "\n",
        "\n",
        "$$\n",
        "W^{(l)} \\leftarrow W^{(l)} - \\alpha \\frac{\\partial E}{\\partial W^{(l)}}\n",
        "$$\n",
        "\n",
        "\n",
        "##  문제\n",
        "\n",
        "1. 위 가중치 업데이트 식이 의미하는 **최적화 기법**이 무엇인지 설명하시오.  \n",
        "2. 위 식에서  \n",
        "$$\n",
        "\\frac{\\partial E}{\\partial W^{(l)}}\n",
        "$$\n",
        "   가 어떻게 계산되는지를 **Chain Rule(연쇄법칙)** 을 이용해 설명하시오.  \n",
        "\n",
        "   (Hint: 세션 자료 하단에 제시된 최종 결과식을 참고헤 도출 과정 서술하면 됨)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "K7U-jSljepw-",
      "metadata": {
        "id": "K7U-jSljepw-"
      },
      "source": [
        "### 답변 1 :\n",
        "\n",
        "### 답변 2 :\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fksAbmqRnd7M",
      "metadata": {
        "id": "fksAbmqRnd7M"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "GIgRo97NVut1",
      "metadata": {
        "id": "GIgRo97NVut1"
      },
      "source": [
        "# 2. DNN 과제"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Ny9dzza0f3kS",
      "metadata": {
        "id": "Ny9dzza0f3kS"
      },
      "source": [
        "다음은 세션 자료 25p의 과제의 내용이다. 자료에 주어진 조건을 바탕으로 아래 문제들을 해결하시오.\n",
        "\n",
        "---\n",
        "\n",
        "### **1. 파라미터 수 직접 계산하기**\n",
        "주어진 신경망 구조(784 - 16 - 16 - 10)를 기준으로 총 학습 파라미터 수(가중치 $W$ 및 편향 $b$)를 직접 계산하시오.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ckt1B2wzgdlI",
      "metadata": {
        "id": "ckt1B2wzgdlI"
      },
      "source": [
        "### 답변 :"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ZAPWAdGFg81y",
      "metadata": {
        "id": "ZAPWAdGFg81y"
      },
      "source": [
        "---\n",
        "\n",
        "### **2. TensorFlow 모델 구현 및 검증**\n",
        "동일한 구조의 DNN을 TensorFlow/Keras 코드로 구현하고, `model.summary()` 출력 결과와 위에서 계산한 값이 일치하는지 확인하시오. (학습 과정은 필요 X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "RgagRLxIk6r1",
      "metadata": {
        "id": "RgagRLxIk6r1"
      },
      "outputs": [],
      "source": [
        "## 1. 적절한 라이브러리를 import하세요\n",
        "import\n",
        "\n",
        "\n",
        "## 2. 모델 설계하기\n",
        "model = models.Sequential([\n",
        "    # 여기에 레이어를 추가하세요\n",
        "])\n",
        "\n",
        "\n",
        "## 3. 모델 summary 출력\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wofnlYRFl0jH",
      "metadata": {
        "id": "wofnlYRFl0jH"
      },
      "source": [
        "---\n",
        "\n",
        "### **3. 결과 비교**\n",
        "1번에서 직접 계산한 학습 파라미터 수와 model.summary() 출력 결과의 Total params 값이\n",
        "서로 일치하는지 확인하시오."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "PJ-HtPs5mqwu",
      "metadata": {
        "id": "PJ-HtPs5mqwu"
      },
      "source": [
        "### 답변 :"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "lnI4oyzXVu6h",
      "metadata": {
        "id": "lnI4oyzXVu6h"
      },
      "source": [
        "# 3. CNN 과제"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96843df4",
      "metadata": {
        "id": "96843df4"
      },
      "source": [
        "---\n",
        "## **Introduction**\n",
        "\n",
        "![](https://miro.medium.com/v2/resize:fit:3744/format:webp/1*SGPGG7oeSvVlV5sOSQ2iZw.png)\n",
        "([Image Credit](https://medium.com/data-science/mnist-handwritten-digits-classification-using-a-convolutional-neural-network-cnn-af5fafbc35e9))\n",
        "\n",
        "Pytorch를 사용하여 이미지와 같이 MNIST 데이터셋을 분류하는 CNN 모델을 구현해봅시다.   \n",
        "Pytorch가 익숙하지 않은 분들은 [다음 튜토리얼](https://docs.pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html)을 참고해주세요.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c2b0f60",
      "metadata": {
        "id": "8c2b0f60"
      },
      "source": [
        "---\n",
        "## **1. Import Libraries & Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8e21858",
      "metadata": {
        "id": "a8e21858"
      },
      "outputs": [],
      "source": [
        "# 필요한 라이브러리를 불러옵니다.\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f26c1020",
      "metadata": {
        "id": "f26c1020"
      },
      "outputs": [],
      "source": [
        "# 이미지 변환 함수를 정의합니다.\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,)) ## 1. 이미지에 Normalize를 하는 이유와 2. 다음과 같은 숫자를 사용한 이유는 무엇일까요? (답은 작성하지 않으셔도 됩니다.)\n",
        "])\n",
        "\n",
        "# 데이터셋을 불러오고, DataLoader를 사용하여 데이터를 로드합니다.\n",
        "trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "testset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bfebc3c1",
      "metadata": {
        "id": "bfebc3c1",
        "outputId": "daf29114-0a97-4720-c37d-9ec59589d5c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training set size: 60000\n",
            "test set size: 10000\n",
            "\n",
            "training set dimension: torch.Size([60000, 28, 28])\n",
            "test set dimension: torch.Size([10000, 28, 28])\n"
          ]
        }
      ],
      "source": [
        "## 데이터셋의 크기와 차원을 확인합니다.\n",
        "print(f'training set size: {len(trainset)}')\n",
        "print(f'test set size: {len(testset)}\\n')\n",
        "\n",
        "print(f'training set dimension: {trainset.data.shape}')\n",
        "print(f'test set dimension: {testset.data.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a787a4e2",
      "metadata": {
        "id": "a787a4e2"
      },
      "source": [
        "---\n",
        "## **2. Define a Convolutional Neural Network**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8ebc72e",
      "metadata": {
        "id": "a8ebc72e"
      },
      "source": [
        "주어진 모델을 다시 한 번 정리해봅시다.\n",
        "\n",
        "\n",
        "**Conv_1** : 3x3 filter 32개, stride: 1, padding: 1, activation = 'relu'   \n",
        "**Pool_2** : 2x2 filter, stride: 2, padding: 0  \n",
        "**Conv_3** : 3x3 filter 64개, stride: 1, padding: 1, activation = 'relu'   \n",
        "**Pool_4** : 2x2 filter, stride: 2, padding: 0   \n",
        "**Dense_5** : 128, activation = 'relu'   \n",
        "**Dense_6** : 10, activation = 'softmax'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1961c671",
      "metadata": {
        "id": "1961c671"
      },
      "outputs": [],
      "source": [
        "# 아래 코드의 빈칸을 채워주세요!\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)\n",
        "        self.conv3 = ## 빈칸 ##\n",
        "        self.pool4 = ## 빈칸 ##\n",
        "        self.dense5 = nn.Linear(64 * 7 * 7, 128)\n",
        "        self.dense6 = ## 빈칸 ##\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.pool2(x)\n",
        "        x = ## 빈칸 ##\n",
        "        x = ## 빈칸 ##\n",
        "        x = torch.flatten(x, 1) # flatten layer: 2D -> 1D\n",
        "        x = ## 빈칸 ##\n",
        "        x = self.dense6(x)\n",
        "        return x\n",
        "\n",
        "cnn = CNN()\n",
        "print(cnn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0735fb3a",
      "metadata": {
        "id": "0735fb3a"
      },
      "outputs": [],
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)\n",
        "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool4 = nn.MaxPool2d(2, 2)\n",
        "        self.dense5 = nn.Linear(64 * 7 * 7, 128)\n",
        "        self.dense6 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.pool2(x)\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = self.pool4(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = F.relu(self.dense5(x))\n",
        "        x = self.dense6(x)\n",
        "        return x\n",
        "\n",
        "cnn = CNN()\n",
        "print(cnn)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2546f642",
      "metadata": {
        "id": "2546f642"
      },
      "source": [
        "#### **문제: 주어진 모델에 대해, layer마다 필요한 parameter의 수를 계산하세요.**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2e2dd6b",
      "metadata": {
        "id": "b2e2dd6b"
      },
      "source": [
        "- Conv_1: (정답)\n",
        "- Pool_2: (정답)\n",
        "- Conv_3: (정답)\n",
        "- Pool_4: (정답)\n",
        "- FC_5: (정답)\n",
        "- FC_6: (정답)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf8b00a9",
      "metadata": {
        "id": "cf8b00a9"
      },
      "outputs": [],
      "source": [
        "# summary를 사용하여 정답과 계산 결과가 일치하는지 확인하세요.\n",
        "# !pip install torchsummary\n",
        "\n",
        "from torchsummary import summary\n",
        "\n",
        "summary(cnn, (1, 28, 28))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fbc55961",
      "metadata": {
        "id": "fbc55961"
      },
      "source": [
        "---\n",
        "## **3. Train a model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9fce42e",
      "metadata": {
        "id": "d9fce42e"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(cnn.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "969c0825",
      "metadata": {
        "id": "969c0825"
      },
      "outputs": [],
      "source": [
        "for epoch in range(3):\n",
        "\n",
        "    running_loss = 0\n",
        "    acc = 0\n",
        "\n",
        "    # training loop\n",
        "    cnn.train()\n",
        "    for i, data in enumerate(trainloader):\n",
        "        inputs, labels = data\n",
        "\n",
        "        # parameter gradient 초기화\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = cnn(inputs) # 모델을 통해 output 계산\n",
        "        loss = criterion(outputs, labels) # loss 계산\n",
        "        loss.backward() # gradient 계산 (backpropagation)\n",
        "        optimizer.step() # parameter 업데이트\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if i % 100 == 99:\n",
        "            print(f'[Epoch: {epoch + 1}, {i + 1:3d}] loss: {running_loss / 100:.3f}')\n",
        "            running_loss = 0\n",
        "\n",
        "    # testing loop\n",
        "    cnn.eval()\n",
        "    for i, data in enumerate(testloader):\n",
        "        inputs, labels = data\n",
        "        outputs = cnn(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        acc += (predicted == labels).sum().item()\n",
        "    acc = acc / len(testloader.dataset)\n",
        "    print(f\"====== Epoch {epoch + 1} Finished, Accuracy: {acc*100:.2f}% ======\")\n",
        "\n",
        "print(f\"\\nTraining finished. Final accuracy: {acc*100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "50e92884",
      "metadata": {
        "id": "50e92884"
      },
      "source": [
        "---\n",
        "## **4. Experiment with the model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a69031ab",
      "metadata": {
        "id": "a69031ab"
      },
      "outputs": [],
      "source": [
        "# 기존의 모델을 원하는 대로 수정해보세요!\n",
        "# ex) layer 추가, kernel size 변경, optimizer 변경, activation 함수 변경, Dropout, etc.\n",
        "class newCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(newCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)\n",
        "        self.conv3 = ## 빈칸 ##\n",
        "        self.pool4 = ## 빈칸 ##\n",
        "        self.dense5 = nn.Linear(64 * 7 * 7, 128)\n",
        "        self.dense6 = ## 빈칸 ##\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.pool2(x)\n",
        "        x = ## 빈칸 ##\n",
        "        x = ## 빈칸 ##\n",
        "        x = torch.flatten(x, 1) # flatten layer: 2D -> 1D\n",
        "        x = ## 빈칸 ##\n",
        "        x = self.dense6(x)\n",
        "        return x\n",
        "\n",
        "new_cnn = newCNN()\n",
        "print(new_cnn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7b063f3",
      "metadata": {
        "id": "e7b063f3"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(new_cnn.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3c143f9",
      "metadata": {
        "id": "e3c143f9"
      },
      "outputs": [],
      "source": [
        "for epoch in range(3):\n",
        "\n",
        "    running_loss = 0\n",
        "    acc = 0\n",
        "\n",
        "    # training loop\n",
        "    new_cnn.train()\n",
        "    for i, data in enumerate(trainloader):\n",
        "        inputs, labels = data\n",
        "\n",
        "        # parameter gradient 초기화\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = new_cnn(inputs) # 모델을 통해 output 계산\n",
        "        loss = criterion(outputs, labels) # loss 계산\n",
        "        loss.backward() # gradient 계산 (backpropagation)\n",
        "        optimizer.step() # parameter 업데이트\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if i % 100 == 99:\n",
        "            print(f'[Epoch: {epoch + 1}, {i + 1:3d}] loss: {running_loss / 100:.3f}')\n",
        "            running_loss = 0\n",
        "\n",
        "    # testing loop\n",
        "    new_cnn.eval()\n",
        "    for i, data in enumerate(testloader):\n",
        "        inputs, labels = data\n",
        "        outputs = new_cnn(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        acc += (predicted == labels).sum().item()\n",
        "    acc = acc / len(testloader.dataset)\n",
        "    print(f\"====== Epoch {epoch + 1} Finished, Accuracy: {acc*100:.2f}% ======\")\n",
        "\n",
        "print(f\"\\nTraining finished. Final accuracy: {acc*100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b866aeb6",
      "metadata": {
        "id": "b866aeb6"
      },
      "source": [
        "### **기존의 모델에서 어떤 부분을 수정하였는지 설명해주세요.**\n",
        "\n",
        "답변 :"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75d3904f",
      "metadata": {
        "id": "75d3904f"
      },
      "source": [
        "### **이러한 변경 사항이 결과에 어떻게 영향을 미쳤나요?**\n",
        "\n",
        "답변 :"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eeeea8a0",
      "metadata": {
        "id": "eeeea8a0"
      },
      "source": [
        "---\n",
        "## **5. (정말 마지막) 이론 문제**\n",
        "convolution이 무엇인지, 그리고 이를 이용하면 이미지의 feature를 추출할 수 있음을 이해하기 위한 문제입니다.\n",
        "\n",
        "다음과 같은 input과 kernel이 존재할 때, 발표 자료의 방식과 같이 feature map을 구하고, 그 결과를 ?에 적으시오.\n",
        "![](https://i.imgur.com/v1wkvhW.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "73830a73",
      "metadata": {
        "id": "73830a73"
      },
      "source": [
        "정답:   \n",
        "? ?   \n",
        "? ?"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
