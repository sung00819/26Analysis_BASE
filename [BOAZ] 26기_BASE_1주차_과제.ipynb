{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "WosjT1B5VeBj",
      "metadata": {
        "id": "WosjT1B5VeBj"
      },
      "source": [
        "# 1. ANN 과제"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "HtX76CHOYLCs",
      "metadata": {
        "id": "HtX76CHOYLCs"
      },
      "source": [
        "## Backpropagation의 가중치 업데이트\n",
        "\n",
        "다음은 17페이지에 제시된 **역전파(Backpropagation) 과정 중 가중치 업데이트 단계**를 나타낸 식이다.\n",
        "\n",
        "가중치 업데이트 단계는 앞선 단계에서 계산된 오차의 기울기를 이용해  \n",
        "손실 함수(Error)를 최소화하는 방향으로 가중치를 조정하는 과정이며,  \n",
        "이때 사용되는 규칙은 대표적인 **최적화 기법**에 해당한다.  \n",
        "\n",
        "\n",
        "$$\n",
        "W^{(l)} \\leftarrow W^{(l)} - \\alpha \\frac{\\partial E}{\\partial W^{(l)}}\n",
        "$$\n",
        "\n",
        "\n",
        "##  문제\n",
        "\n",
        "1. 위 가중치 업데이트 식이 의미하는 **최적화 기법**이 무엇인지 설명하시오.  \n",
        "2. 위 식에서  \n",
        "$$\n",
        "\\frac{\\partial E}{\\partial W^{(l)}}\n",
        "$$\n",
        "   가 어떻게 계산되는지를 **Chain Rule(연쇄법칙)** 을 이용해 설명하시오.  \n",
        "\n",
        "   (Hint: 세션 자료 하단에 제시된 최종 결과식을 참고헤 도출 과정 서술하면 됨)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "K7U-jSljepw-",
      "metadata": {
        "id": "K7U-jSljepw-"
      },
      "source": [
        "### 답변 1 :\n",
        "\n",
        "### 답변 2 :\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ce92ed8",
      "metadata": {},
      "source": [
        "![답변1,2](./ans.jpeg)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fksAbmqRnd7M",
      "metadata": {
        "id": "fksAbmqRnd7M"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "GIgRo97NVut1",
      "metadata": {
        "id": "GIgRo97NVut1"
      },
      "source": [
        "# 2. DNN 과제"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Ny9dzza0f3kS",
      "metadata": {
        "id": "Ny9dzza0f3kS"
      },
      "source": [
        "다음은 세션 자료 25p의 과제의 내용이다. 자료에 주어진 조건을 바탕으로 아래 문제들을 해결하시오.\n",
        "\n",
        "---\n",
        "\n",
        "### **1. 파라미터 수 직접 계산하기**\n",
        "주어진 신경망 구조(784 - 16 - 16 - 10)를 기준으로 총 학습 파라미터 수(가중치 $W$ 및 편향 $b$)를 직접 계산하시오.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ckt1B2wzgdlI",
      "metadata": {
        "id": "ckt1B2wzgdlI"
      },
      "source": [
        "### 답변 : 16*(784+1)+16*(16+1)+10*(16+1)=13002"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ZAPWAdGFg81y",
      "metadata": {
        "id": "ZAPWAdGFg81y"
      },
      "source": [
        "---\n",
        "\n",
        "### **2. TensorFlow 모델 구현 및 검증**\n",
        "동일한 구조의 DNN을 TensorFlow/Keras 코드로 구현하고, `model.summary()` 출력 결과와 위에서 계산한 값이 일치하는지 확인하시오. (학습 과정은 필요 X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "fa5422d6",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,560</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">170</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │        \u001b[38;5;34m12,560\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m272\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m170\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,002</span> (50.79 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m13,002\u001b[0m (50.79 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,002</span> (50.79 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m13,002\u001b[0m (50.79 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "model = models.Sequential([\n",
        "    layers.Dense(16, activation='relu', input_shape=(784,)), \n",
        "    layers.Dense(16, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# 결과 출력\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wofnlYRFl0jH",
      "metadata": {
        "id": "wofnlYRFl0jH"
      },
      "source": [
        "---\n",
        "\n",
        "### **3. 결과 비교**\n",
        "1번에서 직접 계산한 학습 파라미터 수와 model.summary() 출력 결과의 Total params 값이\n",
        "서로 일치하는지 확인하시오."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "PJ-HtPs5mqwu",
      "metadata": {
        "id": "PJ-HtPs5mqwu"
      },
      "source": [
        "### 답변 : 총 13,002개로 일치합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "lnI4oyzXVu6h",
      "metadata": {
        "id": "lnI4oyzXVu6h"
      },
      "source": [
        "# 3. CNN 과제"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96843df4",
      "metadata": {
        "id": "96843df4"
      },
      "source": [
        "---\n",
        "## **Introduction**\n",
        "\n",
        "![](https://miro.medium.com/v2/resize:fit:3744/format:webp/1*SGPGG7oeSvVlV5sOSQ2iZw.png)\n",
        "([Image Credit](https://medium.com/data-science/mnist-handwritten-digits-classification-using-a-convolutional-neural-network-cnn-af5fafbc35e9))\n",
        "\n",
        "Pytorch를 사용하여 이미지와 같이 MNIST 데이터셋을 분류하는 CNN 모델을 구현해봅시다.   \n",
        "Pytorch가 익숙하지 않은 분들은 [다음 튜토리얼](https://docs.pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html)을 참고해주세요.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c2b0f60",
      "metadata": {
        "id": "8c2b0f60"
      },
      "source": [
        "---\n",
        "## **1. Import Libraries & Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "a8e21858",
      "metadata": {
        "id": "a8e21858"
      },
      "outputs": [],
      "source": [
        "# 필요한 라이브러리를 불러옵니다.\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "f26c1020",
      "metadata": {
        "id": "f26c1020"
      },
      "outputs": [],
      "source": [
        "# 이미지 변환 함수를 정의합니다.\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,)) \n",
        "    ])\n",
        "\n",
        "# 데이터셋을 불러오고, DataLoader를 사용하여 데이터를 로드합니다.\n",
        "trainset = datasets.MNIST(root='./Users/seong-yumin/Desktop/boaz/data', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "testset = datasets.MNIST(root='/Users/seong-yumin/Desktop/boaz/data', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "bfebc3c1",
      "metadata": {
        "id": "bfebc3c1",
        "outputId": "daf29114-0a97-4720-c37d-9ec59589d5c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training set size: 60000\n",
            "test set size: 10000\n",
            "\n",
            "training set dimension: torch.Size([60000, 28, 28])\n",
            "test set dimension: torch.Size([10000, 28, 28])\n"
          ]
        }
      ],
      "source": [
        "## 데이터셋의 크기와 차원을 확인합니다.\n",
        "print(f'training set size: {len(trainset)}')\n",
        "print(f'test set size: {len(testset)}\\n')\n",
        "\n",
        "print(f'training set dimension: {trainset.data.shape}')\n",
        "print(f'test set dimension: {testset.data.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a787a4e2",
      "metadata": {
        "id": "a787a4e2"
      },
      "source": [
        "---\n",
        "## **2. Define a Convolutional Neural Network**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8ebc72e",
      "metadata": {
        "id": "a8ebc72e"
      },
      "source": [
        "주어진 모델을 다시 한 번 정리해봅시다.\n",
        "\n",
        "\n",
        "**Conv_1** : 3x3 filter 32개, stride: 1, padding: 1, activation = 'relu'   \n",
        "**Pool_2** : 2x2 filter, stride: 2, padding: 0  \n",
        "**Conv_3** : 3x3 filter 64개, stride: 1, padding: 1, activation = 'relu'   \n",
        "**Pool_4** : 2x2 filter, stride: 2, padding: 0   \n",
        "**Dense_5** : 128, activation = 'relu'   \n",
        "**Dense_6** : 10, activation = 'softmax'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "0735fb3a",
      "metadata": {
        "id": "0735fb3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CNN(\n",
            "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (pool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (dense5): Linear(in_features=3136, out_features=128, bias=True)\n",
            "  (dense6): Linear(in_features=128, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)\n",
        "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool4 = nn.MaxPool2d(2, 2)\n",
        "        self.dense5 = nn.Linear(64 * 7 * 7, 128)\n",
        "        self.dense6 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.pool2(x)\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = self.pool4(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = F.relu(self.dense5(x))\n",
        "        x = self.dense6(x)\n",
        "        return x\n",
        "    \n",
        "\n",
        "cnn = CNN()\n",
        "print(cnn)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2546f642",
      "metadata": {
        "id": "2546f642"
      },
      "source": [
        "#### **문제: 주어진 모델에 대해, layer마다 필요한 parameter의 수를 계산하세요.**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2e2dd6b",
      "metadata": {
        "id": "b2e2dd6b"
      },
      "source": [
        "- Conv_1: (정답)\n",
        "- Pool_2: (정답)\n",
        "- Conv_3: (정답)\n",
        "- Pool_4: (정답)\n",
        "- FC_5: (정답)\n",
        "- FC_6: (정답)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "cf8b00a9",
      "metadata": {
        "id": "cf8b00a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchsummary in /Users/seong-yumin/opt/anaconda3/envs/Torchvision/lib/python3.12/site-packages (1.5.1)\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 28, 28]             320\n",
            "         MaxPool2d-2           [-1, 32, 14, 14]               0\n",
            "            Conv2d-3           [-1, 64, 14, 14]          18,496\n",
            "         MaxPool2d-4             [-1, 64, 7, 7]               0\n",
            "            Linear-5                  [-1, 128]         401,536\n",
            "            Linear-6                   [-1, 10]           1,290\n",
            "================================================================\n",
            "Total params: 421,642\n",
            "Trainable params: 421,642\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.36\n",
            "Params size (MB): 1.61\n",
            "Estimated Total Size (MB): 1.97\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# summary를 사용하여 정답과 계산 결과가 일치하는지 확인하세요.\n",
        "!pip install torchsummary\n",
        "\n",
        "from torchsummary import summary\n",
        "\n",
        "summary(cnn, (1, 28, 28))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fbc55961",
      "metadata": {
        "id": "fbc55961"
      },
      "source": [
        "---\n",
        "## **3. Train a model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "d9fce42e",
      "metadata": {
        "id": "d9fce42e"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(cnn.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "969c0825",
      "metadata": {
        "id": "969c0825"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch: 1, 100] loss: 0.556\n",
            "[Epoch: 1, 200] loss: 0.147\n",
            "[Epoch: 1, 300] loss: 0.098\n",
            "[Epoch: 1, 400] loss: 0.102\n",
            "[Epoch: 1, 500] loss: 0.078\n",
            "[Epoch: 1, 600] loss: 0.066\n",
            "[Epoch: 1, 700] loss: 0.057\n",
            "[Epoch: 1, 800] loss: 0.061\n",
            "[Epoch: 1, 900] loss: 0.054\n",
            "====== Epoch 1 Finished, Accuracy: 98.84% ======\n",
            "[Epoch: 2, 100] loss: 0.039\n",
            "[Epoch: 2, 200] loss: 0.038\n",
            "[Epoch: 2, 300] loss: 0.037\n",
            "[Epoch: 2, 400] loss: 0.048\n",
            "[Epoch: 2, 500] loss: 0.041\n",
            "[Epoch: 2, 600] loss: 0.039\n",
            "[Epoch: 2, 700] loss: 0.032\n",
            "[Epoch: 2, 800] loss: 0.037\n",
            "[Epoch: 2, 900] loss: 0.040\n",
            "====== Epoch 2 Finished, Accuracy: 98.57% ======\n",
            "[Epoch: 3, 100] loss: 0.028\n",
            "[Epoch: 3, 200] loss: 0.023\n",
            "[Epoch: 3, 300] loss: 0.025\n",
            "[Epoch: 3, 400] loss: 0.030\n",
            "[Epoch: 3, 500] loss: 0.035\n",
            "[Epoch: 3, 600] loss: 0.025\n",
            "[Epoch: 3, 700] loss: 0.026\n",
            "[Epoch: 3, 800] loss: 0.026\n",
            "[Epoch: 3, 900] loss: 0.028\n",
            "====== Epoch 3 Finished, Accuracy: 99.12% ======\n",
            "\n",
            "Training finished. Final accuracy: 99.12%\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(3):\n",
        "\n",
        "    running_loss = 0\n",
        "    acc = 0\n",
        "\n",
        "    # training loop\n",
        "    cnn.train()\n",
        "    for i, data in enumerate(trainloader):\n",
        "        inputs, labels = data\n",
        "\n",
        "        # parameter gradient 초기화\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = cnn(inputs) # 모델을 통해 output 계산\n",
        "        loss = criterion(outputs, labels) # loss 계산\n",
        "        loss.backward() # gradient 계산 (backpropagation)\n",
        "        optimizer.step() # parameter 업데이트\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if i % 100 == 99:\n",
        "            print(f'[Epoch: {epoch + 1}, {i + 1:3d}] loss: {running_loss / 100:.3f}')\n",
        "            running_loss = 0\n",
        "\n",
        "    # testing loop\n",
        "    cnn.eval()\n",
        "    for i, data in enumerate(testloader):\n",
        "        inputs, labels = data\n",
        "        outputs = cnn(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        acc += (predicted == labels).sum().item()\n",
        "    acc = acc / len(testloader.dataset)\n",
        "    print(f\"====== Epoch {epoch + 1} Finished, Accuracy: {acc*100:.2f}% ======\")\n",
        "\n",
        "print(f\"\\nTraining finished. Final accuracy: {acc*100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "50e92884",
      "metadata": {
        "id": "50e92884"
      },
      "source": [
        "---\n",
        "## **4. Experiment with the model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a69031ab",
      "metadata": {
        "id": "a69031ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "newCNN(\n",
            "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (pool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (dense5): Linear(in_features=3136, out_features=128, bias=True)\n",
            "  (dense6): Linear(in_features=128, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# 기존의 모델을 원하는 대로 수정해보세요!\n",
        "# ex) layer 추가, kernel size 변경, optimizer 변경, activation 함수 변경, Dropout, etc.\n",
        "\n",
        "class newCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(newCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)\n",
        "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool4 = nn.MaxPool2d(2, 2)\n",
        "        self.dropout = nn.Dropout(0.5)         \n",
        "        self.dense5 = nn.Linear(64 * 7 * 7, 128)\n",
        "        self.dense6 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.pool2(x)\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = self.pool4(x)\n",
        "        x = torch.flatten(x, 1) \n",
        "        x = F.relu(self.dense5(x))\n",
        "        x = self.dropout(x)  \n",
        "        \n",
        "        x = self.dense6(x)\n",
        "        return x\n",
        "\n",
        "new_cnn = newCNN()\n",
        "print(new_cnn)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "e7b063f3",
      "metadata": {
        "id": "e7b063f3"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(new_cnn.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "e3c143f9",
      "metadata": {
        "id": "e3c143f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch: 1, 100] loss: 0.777\n",
            "[Epoch: 1, 200] loss: 0.258\n",
            "[Epoch: 1, 300] loss: 0.187\n",
            "[Epoch: 1, 400] loss: 0.157\n",
            "[Epoch: 1, 500] loss: 0.139\n",
            "[Epoch: 1, 600] loss: 0.131\n",
            "[Epoch: 1, 700] loss: 0.121\n",
            "[Epoch: 1, 800] loss: 0.110\n",
            "[Epoch: 1, 900] loss: 0.105\n",
            "====== Epoch 1 Finished, Accuracy: 98.49% ======\n",
            "[Epoch: 2, 100] loss: 0.090\n",
            "[Epoch: 2, 200] loss: 0.095\n",
            "[Epoch: 2, 300] loss: 0.091\n",
            "[Epoch: 2, 400] loss: 0.074\n",
            "[Epoch: 2, 500] loss: 0.082\n",
            "[Epoch: 2, 600] loss: 0.070\n",
            "[Epoch: 2, 700] loss: 0.070\n",
            "[Epoch: 2, 800] loss: 0.072\n",
            "[Epoch: 2, 900] loss: 0.070\n",
            "====== Epoch 2 Finished, Accuracy: 98.89% ======\n",
            "[Epoch: 3, 100] loss: 0.056\n",
            "[Epoch: 3, 200] loss: 0.060\n",
            "[Epoch: 3, 300] loss: 0.053\n",
            "[Epoch: 3, 400] loss: 0.060\n",
            "[Epoch: 3, 500] loss: 0.069\n",
            "[Epoch: 3, 600] loss: 0.060\n",
            "[Epoch: 3, 700] loss: 0.064\n",
            "[Epoch: 3, 800] loss: 0.055\n",
            "[Epoch: 3, 900] loss: 0.052\n",
            "====== Epoch 3 Finished, Accuracy: 99.11% ======\n",
            "\n",
            "Training finished. Final accuracy: 99.11%\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(3):\n",
        "\n",
        "    running_loss = 0\n",
        "    acc = 0\n",
        "\n",
        "    # training loop\n",
        "    new_cnn.train()\n",
        "    for i, data in enumerate(trainloader):\n",
        "        inputs, labels = data\n",
        "\n",
        "        # parameter gradient 초기화\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = new_cnn(inputs) # 모델을 통해 output 계산\n",
        "        loss = criterion(outputs, labels) # loss 계산\n",
        "        loss.backward() # gradient 계산 (backpropagation)\n",
        "        optimizer.step() # parameter 업데이트\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if i % 100 == 99:\n",
        "            print(f'[Epoch: {epoch + 1}, {i + 1:3d}] loss: {running_loss / 100:.3f}')\n",
        "            running_loss = 0\n",
        "\n",
        "    # testing loop\n",
        "    new_cnn.eval()\n",
        "    for i, data in enumerate(testloader):\n",
        "        inputs, labels = data\n",
        "        outputs = new_cnn(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        acc += (predicted == labels).sum().item()\n",
        "    acc = acc / len(testloader.dataset)\n",
        "    print(f\"====== Epoch {epoch + 1} Finished, Accuracy: {acc*100:.2f}% ======\")\n",
        "\n",
        "print(f\"\\nTraining finished. Final accuracy: {acc*100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b866aeb6",
      "metadata": {
        "id": "b866aeb6"
      },
      "source": [
        "### **기존의 모델에서 어떤 부분을 수정하였는지 설명해주세요.**\n",
        "\n",
        "답변 : dense5직전에 dropout을 추가하였고 모델 구조를 유지했습니다. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75d3904f",
      "metadata": {
        "id": "75d3904f"
      },
      "source": [
        "### **이러한 변경 사항이 결과에 어떻게 영향을 미쳤나요?**\n",
        "\n",
        "답변 :dropout의 추가 효과만을 확인하고자했습니다. 최종 정확도는 99.12%와 99.11%로 유의미한 차이가 없었지만 수정된 모델은 Dropout을 통해 과적합을 방지하기 때문에, 학습에 이용되지 않은 데이터에 대해서는 기존 모델보다 더 안정적인 성능을 기대할 수 있습니다. 에폭이 너무 작고 모델이 간단한 구조이며 기존에도 정확도가 매우 높게 나왔기 때문에 성능에 유의미한 차이가 없었다고 생각합니다. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eeeea8a0",
      "metadata": {
        "id": "eeeea8a0"
      },
      "source": [
        "---\n",
        "## **5. (정말 마지막) 이론 문제**\n",
        "convolution이 무엇인지, 그리고 이를 이용하면 이미지의 feature를 추출할 수 있음을 이해하기 위한 문제입니다.\n",
        "\n",
        "다음과 같은 input과 kernel이 존재할 때, 발표 자료의 방식과 같이 feature map을 구하고, 그 결과를 ?에 적으시오.\n",
        "![](https://i.imgur.com/v1wkvhW.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "73830a73",
      "metadata": {
        "id": "73830a73"
      },
      "source": [
        "정답:   \n",
        "1 0 \n",
        "0 1"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Torchvision",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
